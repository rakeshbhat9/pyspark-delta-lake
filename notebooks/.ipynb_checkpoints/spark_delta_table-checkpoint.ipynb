{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stuck-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Config for notebook - optional\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earlier-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delta lake docs\n",
    "# https://docs.delta.io/latest/delta-intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passing-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "# Instantiate spark session with delta lake\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:0.8.0\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from delta.tables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fourth-bikini",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "913000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+-----+\n",
      "|      date|store|item|sales|\n",
      "+----------+-----+----+-----+\n",
      "|2013-01-01|    1|   1|   13|\n",
      "|2013-01-02|    1|   1|   11|\n",
      "|2013-01-03|    1|   1|   14|\n",
      "|2013-01-04|    1|   1|   13|\n",
      "|2013-01-05|    1|   1|   10|\n",
      "+----------+-----+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in data in to dataframe\n",
    "\n",
    "df = spark.read.option(\"header\",True).csv('../data/train.csv')\n",
    "\n",
    "df.count()\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "irish-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write as delta table.\n",
    "df.write.format(\"delta\").save(\"/home/jovyan/work/lake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "protecting-remainder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "peaceful-cement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "913000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel and readin data from delta lake\n",
    "\n",
    "delta_df = spark.read.format(\"delta\").load(\"../lake\")\n",
    "\n",
    "type(delta_df)\n",
    "\n",
    "delta_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-queue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "registered-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame with a new column\n",
    "new_df = df.withColumn('col_n', df.store + df.item)\n",
    "\n",
    "new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "clean-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write this back to delta lake. Note: without overwrite and mergescehma we will get an error as Delta lake wont allow us to overwrite data with new column\n",
    "\n",
    "new_df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(\"../lake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-archive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "unnecessary-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check Delta table's meta data\n",
    "deltaTable = DeltaTable.forPath(spark, \"../lake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "subtle-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>userId</th>\n",
       "      <th>userName</th>\n",
       "      <th>operation</th>\n",
       "      <th>operationParameters</th>\n",
       "      <th>job</th>\n",
       "      <th>notebook</th>\n",
       "      <th>clusterId</th>\n",
       "      <th>readVersion</th>\n",
       "      <th>isolationLevel</th>\n",
       "      <th>isBlindAppend</th>\n",
       "      <th>operationMetrics</th>\n",
       "      <th>userMetadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-07 12:40:19.961</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'Overwrite', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{'numOutputRows': '913000', 'numOutputBytes': '1776421', 'numFiles': '4'}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-07 12:22:02.304</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WRITE</td>\n",
       "      <td>{'mode': 'ErrorIfExists', 'partitionBy': '[]'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>{'numOutputRows': '913000', 'numOutputBytes': '1773875', 'numFiles': '4'}</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   version               timestamp userId userName operation  \\\n",
       "0        1 2021-04-07 12:40:19.961   None     None     WRITE   \n",
       "1        0 2021-04-07 12:22:02.304   None     None     WRITE   \n",
       "\n",
       "                              operationParameters   job notebook clusterId  \\\n",
       "0      {'mode': 'Overwrite', 'partitionBy': '[]'}  None     None      None   \n",
       "1  {'mode': 'ErrorIfExists', 'partitionBy': '[]'}  None     None      None   \n",
       "\n",
       "   readVersion isolationLevel  isBlindAppend  \\\n",
       "0          0.0           None          False   \n",
       "1          NaN           None           True   \n",
       "\n",
       "                                                            operationMetrics  \\\n",
       "0  {'numOutputRows': '913000', 'numOutputBytes': '1776421', 'numFiles': '4'}   \n",
       "1  {'numOutputRows': '913000', 'numOutputBytes': '1773875', 'numFiles': '4'}   \n",
       "\n",
       "  userMetadata  \n",
       "0         None  \n",
       "1         None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we can see below, Delta lake has history of our initial write and then changes made subsequently.\n",
    "deltaTable.history().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accepting-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_delta_log\r\n",
      "part-00000-457fb9cf-fd52-423d-9af9-c2922d0c85fe-c000.snappy.parquet\r\n",
      "part-00000-bb692ea7-87a1-4af0-b7f3-95189f10bdcf-c000.snappy.parquet\r\n",
      "part-00001-225c2da3-6d10-4561-a7eb-66d51c4e0720-c000.snappy.parquet\r\n",
      "part-00001-a6373976-cac8-45d4-ab3d-120c40bd7222-c000.snappy.parquet\r\n",
      "part-00002-2236d358-9a8e-4d96-bb24-38caecae18d6-c000.snappy.parquet\r\n",
      "part-00002-712810b1-3c68-4e17-9536-246c20c10d4b-c000.snappy.parquet\r\n",
      "part-00003-376097a8-e45b-4d0e-a3fd-7940325b6c65-c000.snappy.parquet\r\n",
      "part-00003-7557dfdc-4c47-42d3-9801-4c80cafa6c21-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "# Below are all parquet files related to above changes\n",
    "!ls ../lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-uniform",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "preliminary-standard",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(913000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date store item sales\n",
       "0  2013-01-01     1    1    13\n",
       "1  2013-01-02     1    1    11\n",
       "2  2013-01-03     1    1    14\n",
       "3  2013-01-04     1    1    13\n",
       "4  2013-01-05     1    1    10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel and now we can read data as of version we are interested in.\n",
    "old_table = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"../lake\")\n",
    "print((old_table.count(), len(old_table.columns)))\n",
    "old_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "knowing-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(913000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store</th>\n",
       "      <th>item</th>\n",
       "      <th>sales</th>\n",
       "      <th>col_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date store item sales  col_n\n",
       "0  2013-01-01     1    1    13    2.0\n",
       "1  2013-01-02     1    1    11    2.0\n",
       "2  2013-01-03     1    1    14    2.0\n",
       "3  2013-01-04     1    1    13    2.0\n",
       "4  2013-01-05     1    1    10    2.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_table = spark.read.format(\"delta\").option(\"versionAsOf\", 1).load(\"../lake\")\n",
    "print((new_table.count(), len(new_table.columns)))\n",
    "new_table.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
